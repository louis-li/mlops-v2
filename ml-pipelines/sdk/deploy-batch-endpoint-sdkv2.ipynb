{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import required libraries\n",
        "from azure.ai.ml import MLClient, command, Input, Output, load_component\n",
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.ai.ml.entities import Data, Environment, ManagedOnlineEndpoint\n",
        "from azure.ai.ml.constants import AssetTypes, InputOutputModes\n",
        "from azure.ai.ml.dsl import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Enter details of your AML workspace\n",
        "subscription_id = \"8480def5-8f7a-4285-99f7-295b61d7b22a\"\n",
        "resource_group = \"mldemorg\"\n",
        "workspace = \"mldemo\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1670200031039
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# get a handle to the workspace\n",
        "ml_client = MLClient(\n",
        "    DefaultAzureCredential(), subscription_id, resource_group, workspace\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "tags": []
      },
      "source": [
        "# Online Endpoint\n",
        "\n",
        "Online endpoints are endpoints that are used for online (real-time) inferencing. They receive data from clients and can send responses back in real time.\n",
        "\n",
        "An **endpoint** is an HTTPS endpoint that clients can call to receive the inferencing (scoring) output of a trained model. It provides:\n",
        "* Authentication using \"key & token\" based auth\n",
        "* SSL termination\n",
        "* A stable scoring URI (endpoint-name.region.inference.ml.azure.com)\n",
        "\n",
        "A **deployment** is a set of resources required for hosting the model that does the actual inferencing.\n",
        "A single endpoint can contain multiple deployments.\n",
        "\n",
        "Features of the managed online endpoint:\n",
        "\n",
        "* **Test and deploy locally** for faster debugging\n",
        "* Traffic to one deployment can also be **mirrored** (copied) to another deployment.\n",
        "* **Application Insights integration**\n",
        "* Security\n",
        "* Authentication: Key and Azure ML Tokens\n",
        "* Automatic Autoscaling\n",
        "* Visual Studio Code debugging\n",
        "\n",
        "**blue-green deployment**: An approach where a new version of a web service is introduced to production by deploying it to a small subset of users/requests before deploying it fully.\n",
        "\n",
        "<center>\n",
        "<img src=\"../imgs/endpoint_concept.png\" width = \"500px\" alt=\"Online Endpoint Concept cli vs sdk\">\n",
        "</center>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "tags": []
      },
      "source": [
        "## 1. Create Online Endpoint\n",
        "\n",
        "We can create an **online endpoint** with cli v2 or sdk v2 using the following syntax:\n",
        "\n",
        "<center>\n",
        "<img src=\"../imgs/create_online_endpoint.png\" width = \"700px\" alt=\"Create Online Endpoint cli vs sdk\">\n",
        "</center>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1669584576485
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import ManagedOnlineEndpoint\n",
        "import random\n",
        "\n",
        "rand = random.randint(0, 10000)\n",
        "\n",
        "endpoint_name = f\"taxi-online-endpoint-{rand}\"\n",
        "# create an online endpoint\n",
        "online_endpoint = ManagedOnlineEndpoint(\n",
        "    name=endpoint_name, \n",
        "    description=\"Taxi online endpoint\",\n",
        "    auth_mode=\"aml_token\",\n",
        ")\n",
        "poller = ml_client.online_endpoints.begin_create_or_update(\n",
        "    online_endpoint,   \n",
        ")\n",
        "\n",
        "poller.wait()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Endpoint creation succeeded\n",
            "ManagedOnlineEndpoint({'public_network_access': 'Enabled', 'provisioning_state': 'Succeeded', 'scoring_uri': 'https://taxi-online-endpoint-6076.eastus2.inference.ml.azure.com/score', 'openapi_uri': 'https://taxi-online-endpoint-6076.eastus2.inference.ml.azure.com/swagger.json', 'name': 'taxi-online-endpoint-6076', 'description': 'Taxi online endpoint', 'tags': {}, 'properties': {'azureml.onlineendpointid': '/subscriptions/8480def5-8f7a-4285-99f7-295b61d7b22a/resourcegroups/mldemorg/providers/microsoft.machinelearningservices/workspaces/mldemo/onlineendpoints/taxi-online-endpoint-6076', 'AzureAsyncOperationUri': 'https://management.azure.com/subscriptions/8480def5-8f7a-4285-99f7-295b61d7b22a/providers/Microsoft.MachineLearningServices/locations/eastus2/mfeOperationsStatus/oe:86d4aa3d-0911-4990-9450-89eef0be8878:2a6bfd1a-b854-4be4-8713-4a677ce0254f?api-version=2022-02-01-preview'}, 'id': '/subscriptions/8480def5-8f7a-4285-99f7-295b61d7b22a/resourceGroups/mldemorg/providers/Microsoft.MachineLearningServices/workspaces/mldemo/onlineEndpoints/taxi-online-endpoint-6076', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/louisli-local2/code/Users/louisli/mlops-v2/ml-pipelines', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7fa9e6e5eef0>, 'auth_mode': 'aml_token', 'location': 'eastus2', 'identity': <azure.ai.ml.entities._credentials.IdentityConfiguration object at 0x7fa9e6e5d2d0>, 'traffic': {}, 'mirror_traffic': {}, 'kind': 'Managed'})\n"
          ]
        }
      ],
      "source": [
        "from azure.ai.ml.exceptions import DeploymentException\n",
        "\n",
        "status = poller.status()\n",
        "if status != \"Succeeded\":\n",
        "    raise DeploymentException(status)\n",
        "else:\n",
        "    print(\"Endpoint creation succeeded\")\n",
        "    endpoint = poller.result()\n",
        "    print(endpoint)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "tags": []
      },
      "source": [
        "## 2. Create Online Deployment\n",
        "\n",
        "To create a deployment to online endpoint, you need to specify the following elements:\n",
        "\n",
        "* Model files (or specify a registered model in your workspace)\n",
        "* Scoring script - code needed to do scoring/inferencing\n",
        "* Environment - a Docker image with Conda dependencies, or a dockerfile\n",
        "* Compute instance & scale settings\n",
        "\n",
        "Note that if you're deploying **MLFlow models**, there's no need to provide **a scoring script** and execution **environment**, as both are autogenerated.\n",
        "\n",
        "We can create an **online deployment** with cli v2 or sdk v2 using the following syntax:\n",
        "\n",
        "<center>\n",
        "<img src=\"../imgs/create_online_deployment.png\" width = \"700px\" alt=\"Create Online Deployment cli vs sdk\">\n",
        "</center>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1669584886619
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Check: endpoint taxi-online-endpoint-6076 exists\n",
            "data_collector is not a known attribute of class <class 'azure.ai.ml._restclient.v2022_02_01_preview.models._models_py3.ManagedOnlineDeployment'> and will be ignored\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "............................................................................................."
          ]
        }
      ],
      "source": [
        "# create online deployment\n",
        "from azure.ai.ml.entities import ManagedOnlineDeployment, Model, Environment\n",
        "\n",
        "blue_deployment = ManagedOnlineDeployment(\n",
        "    name=\"blue\",\n",
        "    endpoint_name=endpoint_name,\n",
        "    model=\"taxi-model@latest\",\n",
        "    instance_type=\"Standard_DS2_v2\",\n",
        "    instance_count=1,\n",
        ")\n",
        "\n",
        "poller = ml_client.online_deployments.begin_create_or_update(\n",
        "    deployment=blue_deployment\n",
        ")\n",
        "poller.wait()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Allocate Traffic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1670199946158
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<azure.core.polling._poller.LROPoller at 0x7fa9e6e5f400>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# allocate traffic\n",
        "# blue deployment takes 100 traffic\n",
        "online_endpoint.traffic = {\"blue\": 100}\n",
        "poller = ml_client.begin_create_or_update(online_endpoint)\n",
        "poller.wait()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Invoke and Test Endpoint\n",
        "\n",
        "We can invoke the **online deployment** with cli v2 or sdk v2 using the following syntax:\n",
        "\n",
        "<center>\n",
        "<img src=\"../imgs/invoke_online_endpoint.png\" width = \"700px\" alt=\"Invoke online endpoint cli vs sdk\">\n",
        "</center>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1668246829854
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'[12.070768414286576, 14.32807957193723]'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# invoke and test endpoint\n",
        "ml_client.online_endpoints.invoke(\n",
        "    endpoint_name=endpoint_name,\n",
        "    request_file=\"../data/taxi-request.json\",\n",
        ")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Batch Endpoint\n",
        "\n",
        "**Batch endpoints** are endpoints that are used to do batch inferencing on large volumes of data over a period of time. \n",
        "\n",
        "**Batch endpoints** receive pointers to data and run jobs asynchronously to process the data in parallel on compute clusters. Batch endpoints store outputs to a data store for further analysis.\n",
        "\n",
        "<center>\n",
        "<img src=\"../imgs/endpoint_batch_concept.png\" width = \"700px\" alt=\"Concept batch endpoint\">\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Create Batch Compute Cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1668247613855
        }
      },
      "outputs": [],
      "source": [
        "# create compute cluster to be used by batch cluster\n",
        "from azure.ai.ml.entities import AmlCompute\n",
        "\n",
        "my_cluster = AmlCompute(\n",
        "    name=\"batch-cluster\",\n",
        "    type=\"amlcompute\", \n",
        "    size=\"STANDARD_DS3_V2\", \n",
        "    min_instances=0, \n",
        "    max_instances=3,\n",
        "    location=\"westeurope\", \t\n",
        ")\n",
        "ml_client.compute.begin_create_or_update(my_cluster)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Create Batch Endpoint\n",
        "\n",
        "We can create the **batch endpoint** with cli v2 or sdk v2 using the following syntax:\n",
        "\n",
        "\n",
        "<center>\n",
        "<img src=\"../imgs/create_batch_endpoint.png\" width = \"700px\" alt=\"Create batch endpoint cli vs sdk\">\n",
        "</center>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1668247623872
        }
      },
      "outputs": [],
      "source": [
        "# create batch endpoint\n",
        "from azure.ai.ml.entities import BatchEndpoint\n",
        "\n",
        "batch_endpoint = BatchEndpoint(\n",
        "    name=\"taxi-batch-endpoint-2\",\n",
        "    description=\"Taxi batch endpoint\",\n",
        "    tags={\"model\": \"taxi-model@latest\"},\n",
        ")\n",
        "\n",
        "ml_client.begin_create_or_update(batch_endpoint)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Create Batch Deployment\n",
        "\n",
        "We can create the **batch deployment** with cli v2 or sdk v2 using the following syntax:\n",
        "\n",
        "<center>\n",
        "<img src=\"../imgs/create_batch_deployment.png\" width = \"700px\" alt=\"Create batch deployment cli vs sdk\">\n",
        "</center>\n",
        "\n",
        "Note that if you're deploying **MLFlow models**, there's no need to provide **a scoring script** and execution **environment**, as both are autogenerated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1668247892781
        }
      },
      "outputs": [],
      "source": [
        "# create batch deployment\n",
        "from azure.ai.ml.entities import BatchDeployment, Model, Environment\n",
        "from azure.ai.ml.constants import BatchDeploymentOutputAction\n",
        "\n",
        "model = \"taxi-model@latest\"\n",
        "\n",
        "batch_deployment = BatchDeployment(\n",
        "    name=\"taxi-batch-dp\",\n",
        "    description=\"this is a sample batch deployment\",\n",
        "    endpoint_name=\"taxi-batch-endpoint-2\",\n",
        "    model=model,\n",
        "    compute=\"batch-cluster\",\n",
        "    instance_count=2,\n",
        "    max_concurrency_per_instance=2,\n",
        "    mini_batch_size=10,\n",
        "    output_action=BatchDeploymentOutputAction.APPEND_ROW,\n",
        "    output_file_name=\"predictions.csv\",\n",
        ")\n",
        "\n",
        "ml_client.begin_create_or_update(batch_deployment)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Set deployment as the default deployment in the endpoint:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1668249096086
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "batch_endpoint = ml_client.batch_endpoints.get(\"taxi-batch-endpoint-2\")\n",
        "batch_endpoint.defaults.deployment_name = batch_deployment.name\n",
        "ml_client.batch_endpoints.begin_create_or_update(batch_endpoint)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Invoke and Test Endpoint\n",
        "\n",
        "We can invoke the **batch deployment** with cli v2 or sdk v2 using the following syntax:\n",
        "\n",
        "<center>\n",
        "<img src=\"../imgs/invoke_batch_deployment.png\" width = \"700px\" alt=\"Invoke batch deployment cli vs sdk\">\n",
        "</center>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1668689480461
        }
      },
      "outputs": [],
      "source": [
        "# invoke and test endpoint\n",
        "from azure.ai.ml import Input\n",
        "from azure.ai.ml.constants import AssetTypes, InputOutputModes\n",
        "\n",
        "input = Input(path=\"../../data/taxi-batch.csv\", \n",
        "              type=AssetTypes.URI_FILE, \n",
        "              mode=InputOutputModes.DOWNLOAD)\n",
        "\n",
        "\n",
        "# invoke the endpoint for batch scoring job\n",
        "ml_client.batch_endpoints.invoke(\n",
        "    endpoint_name=\"taxi-batch-endpoint\",\n",
        "    input=input,\n",
        "    deployment_name=\"taxi-batch-dp\"\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - SDK V2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
